{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/david/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('punkt') ## algorithm for tokenization\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "unreliable_weight = 0.4\n",
    "train['weight'] = train['label_quality'].apply(lambda quality: 1. if quality == 'reliable' else unreliable_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spanish = train[train.language == 'spanish']\n",
    "train_portuguese = train[train.language == 'portuguese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spanish_reliable = train_spanish[train_spanish.label_quality == 'reliable']\n",
    "train_portuguese_reliable = train_portuguese[train_portuguese.label_quality == 'reliable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_categories(df):\n",
    "    grouped = df.groupby(['category']).count()\n",
    "    available_categories = list(grouped[grouped['title'] > 1].index.to_numpy())\n",
    "    filtered = df[df.category.isin(available_categories)]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocessor(doc):\n",
    "    return re.sub('[0-9¡¨ª®°´·º»½¿ø' + string.punctuation + ']', '', doc).lower()\n",
    "\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "portuguese_stemmer = SnowballStemmer('portuguese')\n",
    "\n",
    "def spanish_stemmer_tokenizer(doc):\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [spanish_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def portuguese_stemmer_tokenizer(doc):\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [portuguese_stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elapsed_time(start, message):\n",
    "    end = time.time()\n",
    "    print( message + ': ', end-start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(titles, labels, weights, language='spanish', batches=200, epochs=400, max_features=8000, \n",
    "          min_df=3, max_df=0.7, test_size=0.1):\n",
    "    titles_train, titles_test, y_train, y_test, w_train, w_test = train_test_split(titles, labels, weights, test_size=test_size, random_state=42, stratify=labels)\n",
    "    print(titles_train.shape, titles_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    run_id = uuid.uuid4().hex\n",
    "    print('Run id: ', run_id)\n",
    "    \n",
    "    if language == 'spanish':\n",
    "        stop_words = list(map(lambda word: spanish_stemmer.stem(word), stopwords.words(language)))\n",
    "        vectorizer = CountVectorizer(max_features=max_features, max_df=max_df, min_df=min_df, strip_accents='unicode', \n",
    "                                        stop_words=stop_words, tokenizer=spanish_stemmer_tokenizer, \n",
    "                                        preprocessor=my_preprocessor)\n",
    "    else:\n",
    "        stop_words = list(map(lambda word: portuguese_stemmer.stem(word), stopwords.words(language)))\n",
    "        vectorizer = CountVectorizer(max_features=max_features, max_df=max_df, min_df=min_df, strip_accents='unicode', \n",
    "                                        stop_words=stop_words, tokenizer=portuguese_stemmer_tokenizer, \n",
    "                                        preprocessor=my_preprocessor)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    vectorizer.fit(titles_train)\n",
    "    elapsed_time(start_time, 'Fit vectorizer')\n",
    "    \n",
    "    dump(vectorizer, 'models/' + language + '_vectorizer_' + run_id + '.joblib')\n",
    "    \n",
    "    tokens = vectorizer.get_feature_names()\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train = vectorizer.transform(titles_train)\n",
    "    elapsed_time(start_time, 'Word2Vec X_train')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    X_test = vectorizer.transform(titles_test)\n",
    "    elapsed_time(start_time, 'Word2Vec X_test')\n",
    "    \n",
    "    samples = X_train.shape[0]\n",
    "    print('samples per batch: ', samples//batches)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    \n",
    "    categories = y_train.unique()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            start_time = time.time()\n",
    "            start = (samples * batch)//batches\n",
    "            end = (samples * (batch + 1))//batches\n",
    "            classifier.partial_fit(X_train[ start:end ], y_train[ start:end ], \n",
    "                                   sample_weight=w_train[ start:end ], classes=categories)\n",
    "            if(batch==0):\n",
    "                elapsed_time(start_time, 'Batch')\n",
    "        if epoch % 5 == 0:\n",
    "            y_predicted = classifier.predict(X_test)\n",
    "            score = balanced_accuracy_score(y_true=y_test, y_pred=y_predicted, sample_weight=w_test)\n",
    "            print('finished epoch: ', epoch, 'with score:', score)\n",
    "            dump(classifier, 'models/checkpoint/' + language + '_classifier_' + run_id + '_' + str(epoch) + '.joblib') \n",
    "\n",
    "    y_predicted = classifier.predict(X_test)\n",
    "    score = balanced_accuracy_score(y_true=y_test, y_pred=y_predicted, sample_weight=w_test)\n",
    "    print('Final score: ', score)\n",
    "\n",
    "    dump(classifier, 'models/' + language + '_classifier_' + run_id + '.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered = filter_small_categories(train_portuguese)\n",
    "\n",
    "# train(filtered['title'], filtered['category'], filtered['weight'], language='portuguese', max_features = 4000,\n",
    "#      batches=500, epochs=200, test_size=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9980000,) (20000,) (9980000,) (20000,)\n",
      "Run id:  cd606050dad24c57874bdf03d6da036d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['tambi'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit vectorizer:  2110.368017911911\n",
      "Word2Vec X_train:  2123.940196275711\n",
      "Word2Vec X_test:  4.245254755020142\n",
      "samples per batch:  19960\n",
      "Batch:  1.5368986129760742\n",
      "finished epoch:  0 with score: 0.6962915167066682\n",
      "Batch:  1.3627755641937256\n",
      "Batch:  1.1748230457305908\n",
      "Batch:  1.1630909442901611\n",
      "Batch:  1.2403192520141602\n",
      "Batch:  1.1729037761688232\n",
      "finished epoch:  5 with score: 0.7649088852394931\n",
      "Batch:  1.3285276889801025\n",
      "Batch:  1.167435646057129\n",
      "Batch:  1.2088963985443115\n",
      "Batch:  1.1531434059143066\n",
      "Batch:  1.1601274013519287\n",
      "finished epoch:  10 with score: 0.7756596247771834\n",
      "Batch:  1.344271183013916\n",
      "Batch:  1.1833646297454834\n",
      "Batch:  1.2114191055297852\n",
      "Batch:  1.2492904663085938\n",
      "Batch:  1.1510803699493408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  15 with score: 0.7796035283445066\n",
      "Batch:  1.3869848251342773\n",
      "Batch:  1.1901185512542725\n",
      "Batch:  1.189366340637207\n",
      "Batch:  1.1997926235198975\n",
      "Batch:  1.174189805984497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  20 with score: 0.7830644563643302\n",
      "Batch:  1.3599433898925781\n",
      "Batch:  1.1884722709655762\n",
      "Batch:  1.2048149108886719\n",
      "Batch:  1.2192106246948242\n",
      "Batch:  1.2355983257293701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  25 with score: 0.783806604148177\n",
      "Batch:  1.4095282554626465\n",
      "Batch:  1.1902923583984375\n",
      "Batch:  1.1806635856628418\n",
      "Batch:  1.1831870079040527\n",
      "Batch:  1.194385051727295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  30 with score: 0.7843472742146448\n",
      "Batch:  1.3985562324523926\n",
      "Batch:  1.2078783512115479\n",
      "Batch:  1.1753106117248535\n",
      "Batch:  1.185072660446167\n",
      "Batch:  1.246666431427002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  35 with score: 0.7840816851383829\n",
      "Batch:  1.3660006523132324\n",
      "Batch:  1.161254644393921\n",
      "Batch:  1.1921112537384033\n",
      "Batch:  1.163806438446045\n",
      "Batch:  1.1802904605865479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  40 with score: 0.7853025505623679\n",
      "Batch:  1.2400434017181396\n",
      "Batch:  1.1955256462097168\n",
      "Batch:  1.2245452404022217\n",
      "Batch:  1.2198357582092285\n",
      "Batch:  1.1902623176574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  45 with score: 0.7858406802718934\n",
      "Batch:  1.3220443725585938\n",
      "Batch:  1.200472354888916\n",
      "Batch:  1.2056329250335693\n",
      "Batch:  1.1967213153839111\n",
      "Batch:  1.1684441566467285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  50 with score: 0.7857387713560918\n",
      "Batch:  1.3323299884796143\n",
      "Batch:  1.171705961227417\n",
      "Batch:  1.2017884254455566\n",
      "Batch:  1.179335355758667\n",
      "Batch:  1.2068662643432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  55 with score: 0.7857412969775341\n",
      "Batch:  1.3276722431182861\n",
      "Batch:  1.1634058952331543\n",
      "Batch:  1.2055895328521729\n",
      "Batch:  1.1834776401519775\n",
      "Batch:  1.2086818218231201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  60 with score: 0.78544490738159\n",
      "Batch:  1.3160605430603027\n",
      "Batch:  1.167055368423462\n",
      "Batch:  1.2017898559570312\n",
      "Batch:  1.2234456539154053\n",
      "Batch:  1.1887028217315674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  65 with score: 0.784906748169647\n",
      "Batch:  1.3581159114837646\n",
      "Batch:  1.2218453884124756\n",
      "Batch:  1.2017719745635986\n",
      "Batch:  1.195230484008789\n",
      "Batch:  1.1887061595916748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  70 with score: 0.7847059065999087\n",
      "Batch:  1.3419678211212158\n",
      "Batch:  1.179741382598877\n",
      "Batch:  1.1864898204803467\n",
      "Batch:  1.1787676811218262\n",
      "Batch:  1.1788861751556396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch:  75 with score: 0.7850297494428935\n",
      "Batch:  1.2818958759307861\n",
      "Batch:  1.1539642810821533\n",
      "Batch:  1.1874041557312012\n",
      "Batch:  1.2217772006988525\n",
      "Batch:  1.1726677417755127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-63e007c0da5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train(filtered['title'], filtered['category'], filtered['weight'], language='spanish', max_features = 10000,\n\u001b[0;32m----> 4\u001b[0;31m      batches=500, epochs=200, test_size=0.002)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0ba4bfe6499a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(titles, labels, weights, language, batches, epochs, max_features, min_df, max_df, test_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             classifier.partial_fit(X_train[ start:end ], y_train[ start:end ], \n\u001b[0;32m---> 50\u001b[0;31m                                    sample_weight=w_train[ start:end ], classes=categories)\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0melapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-challenge/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# label_binarize() returns arrays with dtype=np.int64.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# We convert it to np.float64 to support sample_weight consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filtered = filter_small_categories(train_spanish)\n",
    "\n",
    "train(filtered['title'], filtered['category'], filtered['weight'], language='spanish', max_features = 10000,\n",
    "     batches=500, epochs=200, test_size=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
